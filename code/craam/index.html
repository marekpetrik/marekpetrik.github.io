<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>CRAAM: Main Page</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">CRAAM
   &#160;<span id="projectnumber">1.0.0</span>
   </div>
   <div id="projectbrief">RobustandApproximateMarkovDecisionProcesses</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">CRAAM Documentation</div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2>Introduction </h2>
<p>Craam is a C++ library for solving <em>plain</em>, <em>robust</em>, or <em>optimistic</em> Markov decision processes. The library also provides basic tools that enable simulation and construction of MDPs from samples. There is also support for state aggregation and abstraction solution methods.</p>
<p>The library supports standard finite or infinite horizon discounted MDPs [Puterman2005]. Some basic stochazstic shortest path methods are also supported. The library assumes <em>maximization</em> over actions. The states and actions must be finite.</p>
<p>The robust model extends the regular MDPs [Iyengar2005]. The library allows to model uncertainty in <em>both</em> the transitions and rewards, unlike some published papers on this topic. This is modeled by adding an outcome to each action. The outcome is assumed to be minimized by nature, similar to [Filar1997].</p>
<p>In summary, the MDP problem being solved is:</p>
<p class="formulaDsp">
\[v(s) = \max_{a \in \mathcal{A}} \min_{o \in \mathcal{O}} \sum_{s\in\mathcal{S}} ( r(s,a,o,s&#39;) + \gamma P(s,a,o,s&#39;) v(s&#39;) ) ~.\]
</p>
<p>Here, \(\mathcal{S}\) are the states, \(\mathcal{A}\) are the actions, \(\mathcal{O}\) are the outcomes.</p>
<p>Available algorithms are <em>value iteration</em> and <em>modified policy iteration</em>. The library support both the plain worst-case outcome method and a worst case with respect to a base distribution.</p>
<h2>Installation and Build Instruction </h2>
<p>See the README.rst</p>
<h2>Getting Started </h2>
<p>The main interface to the library is through the templated class <a class="el" href="classcraam_1_1GRMDP.html" title="A general robust Markov decision process. ">GRMDP</a>. The templated version of this class enable different definitions of the uncertainty set. The avialable specializations are:</p>
<ul>
<li><a class="el" href="namespacecraam.html#a9d59929435946aa3b9f860ca5d0b051f" title="Regular MDP with discrete actions and one outcome per action. ">craam::MDP</a> : plain MDP with no definition of uncertainty</li>
<li><a class="el" href="namespacecraam.html#a5d936882aaf2071dc0e8b708a4a35bb7" title="An uncertain MDP with discrete robustness. ">craam::RMDP_D</a> : a robust/uncertain with discrete outcomes with the best/worst one chosen</li>
<li><a class="el" href="namespacecraam.html#a81699764382753e44c8806b8959e3414" title="An uncertain MDP with L1 constrained robustness. ">craam::RMDP_L1</a> : a robust/uncertain with discrete outcomes with L1 constraints on the uncertainty</li>
</ul>
<p>States, actions, and outcomes are identified using 0-based contiguous indexes. The actions are indexed independently for each states and the outcomes are indexed independently for each state and action pair.</p>
<p>Transitions are added through function add_transition. New states, actions, or outcomes are automatically added based on the new transition. The actual algorithms are solved using:</p>
<table class="doxtable">
<tr>
<th>Method </th><th>Algorithm  </th></tr>
<tr>
<td><a class="el" href="classcraam_1_1GRMDP.html#a2b035a1f7059ce15e89cb6c2e526ef31" title="Gauss-Seidel varaint of value iteration (not parallelized). ">GRMDP::vi_gs</a> </td><td>Gauss-Seidel value iteration; runs in a single thread. Computes the worst-case outcome for each action. </td></tr>
<tr>
<td><a class="el" href="classcraam_1_1GRMDP.html#a1e16e565fa02d5bec19b96962aef4447" title="Jacobi variant of value iteration. ">GRMDP::vi_jac</a> </td><td>Jacobi value iteration; parallelized with OpenMP. Computes the worst-case outcome for each action. </td></tr>
<tr>
<td><a class="el" href="classcraam_1_1GRMDP.html#a4f15849a48bd6c928224e9b7aa156727" title="Modified policy iteration using Jacobi value iteration in the inner loop. ">GRMDP::mpi_jac</a> </td><td>Jacobi modified policy iteration; parallelized with OpenMP. Computes the worst-case outcome for each action. Generally, modified policy iteration is vastly more efficient than value iteration. </td></tr>
<tr>
<td><a class="el" href="classcraam_1_1GRMDP.html#a35823e3e47b52f8684e26ae92361beba" title="Value function evaluation using Jacobi iteration for a fixed policy. ">GRMDP::vi_jac_fix</a> </td><td>Jacobi value iteration for policy evaluation; parallelized with OpenMP. Computes the worst-case outcome for each action. </td></tr>
</table>
<p>For uncertain MDPs, each method supports average, robust, and optimistic computation modes.</p>
<p>The following is a simple example of formulating and solving a small MDP.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;RMDP.hpp&quot;</span></div><div class="line"><span class="preprocessor">#include &quot;modeltools.hpp&quot;</span></div><div class="line"></div><div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div><div class="line"><span class="preprocessor">#include &lt;vector&gt;</span></div><div class="line"></div><div class="line"><span class="keyword">using namespace </span><a class="code" href="namespacecraam.html">craam</a>;</div><div class="line"></div><div class="line"><span class="keywordtype">int</span> main(){</div><div class="line">    <a class="code" href="classcraam_1_1GRMDP.html">MDP</a> mdp(3);</div><div class="line"></div><div class="line">    <span class="comment">// transitions for action 0</span></div><div class="line">    <a class="code" href="namespacecraam.html#ae256dd56144dedc246525e537fe1e241">add_transition</a>(mdp,0,0,0,1,0);</div><div class="line">    <a class="code" href="namespacecraam.html#ae256dd56144dedc246525e537fe1e241">add_transition</a>(mdp,1,0,0,1,1);</div><div class="line">    <a class="code" href="namespacecraam.html#ae256dd56144dedc246525e537fe1e241">add_transition</a>(mdp,2,0,1,1,1);</div><div class="line"></div><div class="line">    <span class="comment">// transitions for action 1</span></div><div class="line">    <a class="code" href="namespacecraam.html#ae256dd56144dedc246525e537fe1e241">add_transition</a>(mdp,0,1,1,1,0);</div><div class="line">    <a class="code" href="namespacecraam.html#ae256dd56144dedc246525e537fe1e241">add_transition</a>(mdp,1,1,2,1,0);</div><div class="line">    <a class="code" href="namespacecraam.html#ae256dd56144dedc246525e537fe1e241">add_transition</a>(mdp,2,1,2,1,1.1);</div><div class="line"></div><div class="line">    <span class="comment">// solve using Jacobi value iteration</span></div><div class="line">    <span class="keyword">auto</span>&amp;&amp; re = mdp.mpi_jac(<a class="code" href="namespacecraam.html#a28345a790e3a8a01c57a7e509837970bab1897515d548a960afe49ecf66a29021">Uncertainty::Average</a>,0.9);</div><div class="line"></div><div class="line">    <span class="keywordflow">for</span>(<span class="keyword">auto</span> v : re.valuefunction){</div><div class="line">        cout &lt;&lt; v &lt;&lt; <span class="stringliteral">&quot; &quot;</span>;</div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="keywordflow">return</span> 0;</div><div class="line">}</div></div><!-- fragment --><p>To compile the file, run:</p>
<div class="fragment"><div class="line">$ g++ -std=c++11 -I&lt;path_to_RAAM.h&gt; -L . -lcraam simple.cpp</div></div><!-- fragment --><h2>Common Use Cases </h2>
<ol type="1">
<li>Formulate an uncertain MDP</li>
<li>Compute a solution to an uncertain MDP</li>
<li>Compute value of a fixed policy</li>
<li>Compute an occupancy frequency</li>
<li>Simulate transitions of an MDP</li>
<li>Construct MDP from samples</li>
<li>Simulate a general domain</li>
</ol>
<h2>General Assumptions </h2>
<ul>
<li><a class="el" href="classcraam_1_1Transition.html" title="Represents sparse transition probabilities and rewards from a single state. ">Transition</a> probabilities must be non-negative but do not need to add up to one</li>
<li>Transitions with 0 probabilities may be omitted, except there must be at least one target state in each transition</li>
<li><b>State with no actions</b>: A terminal state with value 0</li>
<li><b>Action with no outcomes</b>: Terminates with an error</li>
<li><b>Outcome with no target states</b>: Terminates with an error</li>
</ul>
<h2>References </h2>
<p>[Filar1997] Filar, J., &amp; Vrieze, K. (1997). Competitive Markov decision processes. Springer.</p>
<p>[Puterman2005] Puterman, M. L. (2005). Markov decision processes: Discrete stochastic dynamic programming. Handbooks in operations research and management …. John Wiley &amp; Sons, Inc.</p>
<p>[Iyengar2005] Iyengar, G. N. G. (2005). Robust dynamic programming. Mathematics of Operations Research, 30(2), 1–29.</p>
<p>[Petrik2014] Petrik, M., Subramanian S. (2014). RAAM : The benefits of robustness in approximating aggregated MDPs in reinforcement learning. In Neural Information Processing Systems (NIPS).</p>
<p>[Petrik2016] Petrik, M., &amp; Luss, R. (2016). Interpretable Policies for Dynamic Product Recommendations. In Uncertainty in Artificial Intelligence (UAI). </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Tue Jun 27 2017 09:21:37 for CRAAM by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
